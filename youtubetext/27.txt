YouTube Community Guidelines & Policies - How YouTube Works Our commitments Managing harmful content How does YouTube manage harmful content? Standing up to hate How does YouTube protect the community from hate and harassment? Fighting misinformation How does YouTube combat misinformation? Curbing extremist content How does YouTube prevent radicalization? Supporting political integrity How does YouTube support civic engagement and election integrity? Preventing bias What does YouTube do to prevent bias? Fostering child safety How does YouTube help keep kids protected on the platform? Protecting user data How does YouTube maintain user privacy? Safeguarding copyright How does YouTube protect copyrighted content? Sharing revenue How does YouTube make money? Promoting digital wellbeing How does YouTube support users’ digital wellbeing? Responding to COVID-19 How is YouTube supporting users during COVID-19? Product features YouTube Search How our search tool can help you find content you'll love Recommended videos How we recommend content we think you'll want to watch News and information How we provide context for your search results and videos Monetization for Creators How Creators earn money on YouTube YouTube Live How you can reach your community in real time with Live and Premieres User settings Privacy controls How we protect your information and what you can do to control your privacy Ad Settings How our advertising works and how to customize your ad experience Parental controls How you can create a family friendly experience Autoplay How Autoplay works and how to turn it off Rules and policies Policies overview How our rules and policies help keep our platform safe Community Guidelines How we define what we do and don’t allow on YouTube Copyright How we help Creators responsibly manage their content Monetization policies How Creators can monetize their content as part of the YouTube Partner Program Legal removals How we approach content that violates local law Progress and impact Progress on managing harmful content How we’re progressing with our responsibility efforts Our impact How creative entrepreneurs are transforming their lives and communities Culture and trends How to better understand the next generation of Creators and artists Our commitments Managing harmful content Standing up to hate Fighting misinformation Curbing extremist content Supporting political integrity Preventing bias Fostering child safety Protecting user data Safeguarding copyright Sharing revenue Promoting digital wellbeing Responding to COVID-19 Product features YouTube Search Recommended videos News and information Monetization for Creators YouTube Live User settings Privacy controls Ad Settings Parental controls Autoplay Rules and policies Policies overview Community Guidelines Copyright Monetization policies Legal removals Progress and impact Progress on managing harmful content Our impact Culture and trends Rules and policies Community Guidelines Community Guidelines Developing policies Detecting violations Flagging content Enforcing policies Overview Our Community Guidelines are designed to ensure our community stays protected. They set out what’s allowed and not allowed on YouTube, and apply to all types of content on our platform, including videos, comments, links, and thumbnails. You'll find a full list of our Community Guidelines below: Spam & deceptive practices Fake Engagement Impersonation Links in content Spam, deceptive practices & scams Sensitive content Child safety Custom thumbnails Nudity and sexual content Suicide and self injury Violent or dangerous content Harassment and cyberbullying Harmful or dangerous content Hate speech Violent criminal organizations Violent or graphic content COVID-19 misinfo policy Regulated goods Content featuring firearms Sale of Illegal or Regulated goods More Additional policies How do we develop new policies and update existing ones? Each of our policies is carefully thought through so they are consistent, well-informed, and can be applied to content from around the world. They’re developed in partnership with a wide range of external industry and policy experts, as well as YouTube Creators. New policies go through multiple rounds of testing before they go live to ensure our global team of content reviewers can apply them accurately and consistently. This work is never finished, and we are always evaluating our policies to understand how we can better strike a balance between keeping the YouTube community protected and giving everyone a voice. How does YouTube identify content that violates Community Guidelines? With hundreds of hours of new content uploaded to YouTube every minute, we use a combination of people and machine learning to detect problematic content at scale. Machine learning is well-suited to detect patterns, which helps us to find content similar to other content we’ve already removed, even before it’s viewed. We also recognize that the best way to quickly remove content is to anticipate problems before they emerge. Our Intelligence Desk monitors the news, social media, and user reports to detect new trends surrounding inappropriate content, and works to make sure our teams are prepared to address them before they can become a larger issue. Is there a way for the broader community to flag harmful content? Though we are determined to continue reducing exposure to videos that violate our policies and have tasked over 10,000 people with detecting, reviewing, and removing content that violates our guidelines, the YouTube community also plays an important role in flagging content they think is inappropriate. If you see content that you think violates Community Guidelines, you can use our flagging feature to submit content for review. We developed the YouTube Trusted Flagger program to provide robust content reporting processes to non-governmental organizations (NGOs) with expertise in a policy area, government agencies, and individuals with high flagging accuracy rates. Participants receive training on YouTube policies and have a direct path of communication with our Trust & Safety specialists. Videos flagged by Trusted Flaggers are not automatically removed. They are subject to the same human review as videos flagged by any other user, but we may expedite review by our teams. NGOs also receive occasional online training on YouTube policies. What action does YouTube take for content that violates Community Guidelines? Machine learning systems help us identify and remove spam automatically, as well as remove re-uploads of content we’ve already reviewed and determined violates our policies. YouTube takes action on other flagged videos after review by trained human reviewers. They assess whether the content does indeed violate our policies, and protect content that has an educational, documentary, scientific, or artistic purpose. Our reviewer teams remove content that violates our policies and age-restrict content that may not be appropriate for all audiences. Community Guidelines Strikes If our reviewers decide that content violates our Community Guidelines, we remove the content and send a notice to the Creator. The first time a Creator violates our Community Guidelines, they receive a warning with no penalty to the channel. After one warning, we’ll issue a Community Guidelines strike to the channel and the account will have temporary restrictions including not being allowed to upload videos, live streams, or stories for a 1-week period. Channels that receive three strikes within a 90-day period will be terminated. Channels that are dedicated to violating our policies or that have a single case of severe abuse of the platform, will bypass our strikes system and be terminated. All strikes and terminations can be appealed if the Creator believes there was an error, and our teams will re-review the decision. Resources Learn more about Community Guidelines strikes Appeal a Community Guidelines strike Age-Restricting Content Sometimes content doesn't violate our Community Guidelines, but may not be appropriate for viewers under 18 years of age. In these cases, our review team will place an age restriction on the video so it will not be visible to viewers under 18 years of age, logged-out users, or to those who have Restricted Mode enabled. Creators can also choose to age restrict their own content at upload if they think it’s not suitable for younger audiences. Resources Learn more about age-restricted content Related articles Progress on managing harmful content Read more Managing harmful content Read more Legal removals Read more Connect About YouTube About Blog How YouTube Works Jobs Press YouTube Culture & Trends Products YouTube Go YouTube Kids YouTube Music YouTube Originals YouTube Premium YouTube Select YouTube Studio YouTube TV For Business Developers YouTube Advertising For Creators Creating for YouTube Kids Creator Academy Creator Research Creator Services Directory YouTube Artists YouTube Creators YouTube NextUp YouTube Space YouTube VR Our Commitments Creators for Change CSAI Match Social Impact About YouTube Products For Business For Creators Our Commitments About Blog How YouTube Works Jobs Press YouTube Culture & Trends YouTube Go YouTube Kids YouTube Music YouTube Originals YouTube Premium YouTube Select YouTube Studio YouTube TV Developers YouTube Advertising Creating for YouTube Kids Creator Academy Creator Research Creator Services Directory YouTube Artists YouTube Creators YouTube NextUp YouTube Space YouTube VR Creators for Change CSAI Match Social Impact Policies & Safety Copyright Brand Guidelines Privacy Terms Help English Deutsch (Österreich) English (Australia) Nederlands (België) ?????????? (?????????) português (Brasil) English (Canada) ??eština (?eská republika) Deutsch (Deutschland) dansk (Danmark) eesti (Eesti) español (España) suomi (Suomi) français (France) ???????? (??????) hrvatski (Hrvatska) magyar (Magyarország) Bahasa Indonesia (Bahasa Indonesia) English (Ireland) English (India) italiano (Italia) ??? (??) ??? (????) lietuvi? (Lietuva) Deutsch (Luxemburg) latviešu (Latvija) Nederlands (Nederland) polski (Polska) português (Portugal) român? (România) ????????? (?????????) svenska (Sverige) slovenš??ina (Slovenija) sloven??ina (Slovensko) Türkçe (Türkiye) English (United Kingdom) ??????? Deutsch (Belgien) ???????? (????????) English (Belgium) English (Malta) español (Estados Unidos) français (Belgique) français (Canada) français (Luxembourg) ??????? (????) ????? (??????) Kiswahili Türkçe (K?br?s)